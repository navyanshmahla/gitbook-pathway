# Diving Deeper: LLM Architecture Components

In the forthcoming video, we provide a detailed explanation of the essential components that constitute a Large Language Model's architecture. This video aims to extend your comprehension of the LLM architecture, contributing to your foundational understanding of the field.

{% embed url="https://youtu.be/OXZQBXBvOR4?t=704" %}

### In this video, we've learned about

* The User Interface Component designed to pose questions
* The Storage Layer, which utilises Vector DB or Vector Indexes
* The Service, Chain, or Pipeline Layer, which is instrumental in the model's functioning (with a brief mention of the Chain Library used for chaining prompts)
* Summary of our learnings around LLM Architecture Components

Let's look at a cleaner architecture diagram, and various steps of the pipeline and summarize the advantages of RAG based on what we've understood so far.

\
